{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading all Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\envs\\THINAM\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import math\n",
    "import graphviz\n",
    "import scipy\n",
    "# import ggplot\n",
    "\n",
    "# from pandas_summary import DataFrameSummary\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from IPython.display import display\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import forest\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from scipy.cluster import hierarchy as hc\n",
    "from pdpbox import pdp\n",
    "from plotnine import *\n",
    "# from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_df(df, y_fld=None, skip_flds=None, ignore_flds=None, do_scale=False, na_dict=None, prepoc_fn=None, max_n_cat=None,\n",
    "           subset=None, mapper=None):\n",
    "    if not ignore_flds: ignore_flds=[]\n",
    "    if not skip_flds: skip_flds=[]\n",
    "    if subset:\n",
    "        df = get_sample(df, subset)\n",
    "    else:\n",
    "        df = df.copy()\n",
    "    ignored_flds = df.loc[:, ignore_flds]\n",
    "    df.drop(ignore_flds, axis=1, inplace=True)\n",
    "    if prepoc_fn: prepoc_fn(df)\n",
    "    if y_fld is None: y=None\n",
    "    else:\n",
    "        if not is_numeric_dtype(df[y_fld]): df[y_fld] = pd.Categorical(df[y_fld]).codes\n",
    "        y = df[y_fld].values\n",
    "        skip_flds += [y_fld]\n",
    "    df.drop(skip_flds, axis=1, inplace=True)\n",
    "    \n",
    "    if na_dict is None: na_dict = {}\n",
    "    else: na_dict = na_dict.copy()\n",
    "    na_dict_initial = na_dict.copy()\n",
    "    for n, c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n",
    "    if len(na_dict_initial.keys()) > 0:\n",
    "        df.drop([a + '_na' for a in list(set(na_dict.keys()) - set(na_dict_initial.keys()))], axis=1, inplace=True)\n",
    "    if do_scale: mapper = scale_vars(df, mapper)\n",
    "    for n, c in df.items(): numericalize(df, c, n, max_n_cat)\n",
    "    df = pd.get_dummies(df, dummy_na=True)\n",
    "    df = pd.concat([ignored_flds, df], axis=1)\n",
    "    res = [df, y, na_dict]\n",
    "    if do_scale: res = res + [mapper]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_missing(df, col, name, na_dict):\n",
    "    if is_numeric_dtype(col):\n",
    "        if pd.isnull(col).sum() or (name in na_dict): \n",
    "            df[name + '_na'] = pd.isnull(col)\n",
    "            filler = na_dict[name] if name in na_dict else col.median()\n",
    "            df[name] = col.fillna(filler)\n",
    "            na_dict[name] = filler\n",
    "    return na_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize(df, col, name, max_n_cat):\n",
    "    if not is_numeric_dtype(col) and (max_n_cat is None or col.nunique()>max_n_cat):\n",
    "        df[name] = col.cat.codes+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(df, n):\n",
    "    idxs = sorted(np.random.permutation(len(df))[:n])\n",
    "    return df.iloc[idxs].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_rf_samples(n):\n",
    "    forest._generate_sample_indices = (lambda rs, n_samples:\n",
    "                                      forest.check_random_state(rs).randit(0, n_samples, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_rf_samples():\n",
    "    forest._generate_sample_indices = (lambda rs, n_samples:\n",
    "                                      forest.check_random_state(rs).randit(0, n_samples, n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_vals(a, n):\n",
    "    return a[:n].copy(), a[n:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(x, y):\n",
    "    return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m):\n",
    "    res = [rmse(m.predict(X_train), y_train),\n",
    "          rmse(m.predict(X_valid), y_valid),\n",
    "          m.score(X_train, y_train),\n",
    "          m.score(X_valid, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'):\n",
    "        res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:\\\\Users\\\\DELL\\\\Blue Book for Bulldozers\\\\Train.csv\"\n",
    "df_raw = pd.read_feather('tmp/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn, y_trn, nas = proc_df(df_raw, 'SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_valid = 12000\n",
    "n_trn = len(df_trn) - n_valid\n",
    "\n",
    "X_train, X_valid = split_vals(df_trn, n_trn)\n",
    "y_train, y_valid = split_vals(y_trn, n_trn)\n",
    "raw_train, raw_valid = split_vals(df_raw, n_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sub = X_train[['YearMade', 'MachineHoursCurrentMeter']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest @ Tree Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeEnsemble():\n",
    "    \n",
    "    def __init__(self, x, y, n_trees, sample_sz, min_leaf=5):\n",
    "        np.random.seed(42)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.sample_sz = sample_sz\n",
    "        self.min_leaf = min_leaf\n",
    "        self.trees = [self.create_tree() for i in range(n_trees)]\n",
    "    \n",
    "    def create_tree(self):\n",
    "        rnd_idxs = np.random.permutation(len(self.y))[:self.sample_sz]\n",
    "        return DecisionTree(self.x.iloc[rnd_idxs], self.y[rnd_idxs], min_leaf=self.min_leaf)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.mean([t.predict(x) for t in self.trees], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    \n",
    "    def __init__(self, x, y, idxs=None, min_leaf=5):\n",
    "        if idxs is None:\n",
    "            idxs = np.arange(len(y))\n",
    "        self.x, self.y = x, y\n",
    "        self.idxs =idxs\n",
    "        self.min_leaf = min_leaf\n",
    "        self.n, self.c = len(idxs), x.shape[1]\n",
    "        self.val = np.mean(y[idxs])\n",
    "        self.score = float('inf')\n",
    "        self.find_varsplit()\n",
    "        \n",
    "    def find_varsplit(self):\n",
    "        for i in range(self.c):\n",
    "            self.find_better_split(i)\n",
    "            \n",
    "    def fing_better_split(self, var_idx):\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def split_name(self):\n",
    "        return self.x.columns[self.var_idx]\n",
    "    \n",
    "    @property\n",
    "    def split_col(self):\n",
    "        return self.x.values[self.idxs, self.var_idx]\n",
    "    \n",
    "    @property\n",
    "    def is_leaf(self):\n",
    "        return self.score == float('inf')\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = f'n: {self.n}; val: {self.val}'\n",
    "        if not self.is_leaf:\n",
    "            s += f'score: {self.score}; split: {self.split}; var: {self.split_name}'\n",
    "            return s\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
